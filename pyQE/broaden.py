import numpy as np
from tqdm import tqdm, trange
from multiprocessing import Pool
from multiprocessing.shared_memory import SharedMemory
from multiprocessing import Pool
from time import time
class SharedNumpyArray:
    '''
    Wraps a numpy array so that it can be shared quickly among processes,
    avoiding unnecessary copying and (de)serializing.
    '''
    def __init__(self, array):
        '''
        Creates the shared memory and copies the array therein
        '''
        # create the shared memory location of the same size of the array
        self._shared = SharedMemory(create=True, size=array.nbytes)
        
        # save data type and shape, necessary to read the data correctly
        self._dtype, self._shape = array.dtype, array.shape
        
        # create a new numpy array that uses the shared memory we created.
        # at first, it is filled with zeros
        res = np.ndarray(
            self._shape, dtype=self._dtype, buffer=self._shared.buf
        )
        
        # copy data from the array to the shared memory. numpy will
        # take care of copying everything in the correct format
        res[:] = array[:]

    def read(self):
        '''
        Reads the array from the shared memory without unnecessary copying.
        '''
        # simply create an array of the correct shape and type,
        # using the shared memory location we created earlier
        return np.ndarray(self._shape, self._dtype, buffer=self._shared.buf)

    def copy(self):
        '''
        Returns a new copy of the array stored in shared memory.
        '''
        return np.copy(self.read_array())
        
    def unlink(self):
        '''
        Releases the allocated memory. Call when finished using the data,
        or when the data was copied somewhere else.
        '''
        self._shared.close()
        self._shared.unlink()



def get_res(args):
    """
    Uses the input arguments as basis onto which we perform the Gaussian broadening
    Arrays are read in as :class:`SharedNumpyArray` and then read /written directly
    from the shared buffer for performance.

    This function takes a single tuple of arguments (so that the function can be pickled)
    that are in the following order.

    Parameters
    ----------
    args : tuple of subsuquent arguments
        strf : :class:`SharedNumpyArray`
            - the instance of the structure factor over which the function broadens
        ii   : integer
            - The index of the unbroadened array over which we sum
        kgx  : :class:`SharedNumpyArray`
            - shared kgridx array onto which we evaluate the broadened structure factor
        kgy  : :class:`SharedNumpyArray`
            - analagous to kgx but for the second dimension
        sx   : float
            - Gaussian broadening in the x dimension
        sy   : float
            - As above for y dimension
        norm : float
            - Normalization factor for the broadening
        d1, d2 : int
            - Array indices corresponding to the dimensions mapped to `x` and `y` 
        res  : :class:`SharedNumpyArray`
            - Array that stores the summed results 

    
    """
    strf, ii, kgx, kgy, sx, sy, norm, d1, d2, res = args
    df = strf.read()
    sf_ii_1 = df[ii,d1]
    sf_ii_2 = df[ii,d2]
    sf_ii = df[ii, -1]
    resd = res.read()
    resd += norm * sf_ii  * (np.exp(-(sf_ii_1-kgx.read())**2 / sx**2 / 2)) * (np.exp(-(sf_ii_2-kgy.read())**2 / sy**2 / 2))
    return

def broaden(arr, rotation = None, steps=10_000, ksteps1=250, ksteps2=250, kmin=-5, kmax=5, dim1=0, dim2=1, Np=400_000, parallel=False, rotate_broadened=False):
    """
    This function performs the broadening on the structure factor. It has parallel and serial options, but as of now the parallel
    processing is actually more expensive owing to still some memory copying of massive arrays...

    If the option `parallel` is passed, it will start the parallel calculation, but should the user keyboard interupt the parallel
    calculation, it will automatically continue in serial mode to ensure the array is indeed broadened and returned.

    Parameters
    ----------
    arr         :       `numpy.ndarray`, shape (N,4)
        - The array with 3D coordinates and the intensity at that coordinate
    rotation    :       dictionary
        - Dictionary containing the rotation parameters. It contains the plane_dir and plane_val values
        used in the DISCA calculation, as well as the rotation matrix generated by :func:`pyQE.disca.getRotationMatrix`.
        It further contains a float `clip_threshold` which ensures that the antirotated values align with the original value of
        plane_val in the plane_dir direction

        Keys
        ----

        matrix      :       `numpy.ndarray`, shape(3,3)
            - Real valued rotation matrix that should be applied to antirotate the coordinates (inverse of the matrix)
              used to rotate them in the first place
        plane_dir   :       integer
            - Cartesian index (zero-valued) of the evaluation plane
        plane_val   :       float
            - The value of the evaluation plane in the direction normal to the plane (plane_dir)
        clip_threshold  :   float
            - Values below this are set to the plane_val in the plane_dir direction

    steps       :       integer
        - The number of points from the original array to consider in the broadening
            (this allows for potential parallelization of this function)
    ksteps1     :       integer
        - The number of steps in the first broadened dimension 
    ksteps2     :       integer
        - See above for second broadened dimension
    kmin        :       float
        - Minimum value for each broadened dimension
    kmax        :       float
        - Max value as above
    dim1        :       integer
        - Cartesian index of first broadened dimension
    dim2        :       integer
        - Cartesian index of second broadened dimension
    Np          :       float
        - Normalization factor by which the intensities are scaled
    parallel    :       bool
        - Logical dictating if parallel computation is performed
    rotated_broadened       :       bool
        - Logical dictating if the final broadened array should be rotated back into the
          original coordinates. Keeping this false allows for ready visualization of the 
          plane of intensities (only need the first two dimensions to interpolate the
          values onto a grid with, for example, `scipy.interpolate.griddata`). 


    Returns
    -------


    
    """
    
    serial = not parallel 
    completed = False
    structure_fact = arr[:steps, :]
    structure_fact_out = np.zeros((ksteps1, ksteps2))

    kgridx = kmin + np.arange(0,ksteps1,1)*(kmax - kmin) / (ksteps1 - 1)
    sf_smearingx = (kmax-kmin) / ksteps1

    kgridy = kmin + np.arange(0,ksteps2,1)*(kmax - kmin) / (ksteps2 - 1)
    sf_smearingy = (kmax-kmin) / ksteps2

    if rotation is not None:
        Rmat = rotation['matrix']
        plane_dir = rotation['plane_dir']
        plane_val = rotation['plane_val']
        clipping = rotation['clip_threshold']
        ORIGIN = np.average(structure_fact[:,:3], axis=0)
        structure_fact[:,:3] = np.transpose(Rmat @ (structure_fact[:,:3]-ORIGIN).T) + ORIGIN
        structure_fact[:,:3][:,plane_dir] = np.where(np.abs(structure_fact[:,:3][:,plane_dir])<clipping, plane_val, structure_fact[:,:3][:,plane_dir])
    kgridx = kgridx.reshape(-1,1)
    kgridy = kgridy.reshape(1,-1)
    NORM = 1 /sf_smearingx / np.sqrt(2*np.pi) / sf_smearingy / np.sqrt(2*np.pi)
    if parallel:
        shared_structure_fact = SharedNumpyArray(structure_fact)
        shared_structure_fact_out = SharedNumpyArray(structure_fact_out)
        shared_kgridx = SharedNumpyArray(kgridx)
        shared_kgridy = SharedNumpyArray(kgridy)

        try:
            with Pool(processes=6) as pool:
                tasks = ((shared_structure_fact, i, shared_kgridx, shared_kgridy, sf_smearingx, sf_smearingy, NORM, dim1, dim2, shared_structure_fact_out ) for i in range(steps))
                result = pool.imap(get_res, tasks)
                for res in tqdm(result, total=steps):
                    pass
                    # res.unlink()
                completed = True
        except KeyboardInterrupt:
            serial = True
            parallel = False

        shared_structure_fact.unlink()
        shared_kgridx.unlink()
        shared_kgridy.unlink()
        shared_structure_fact_out.unlink()

    if serial and not parallel and not completed:
        # from scipy.interpolate import griddata
        # from scipy.ndimage import gaussian_filter
        # qx = np.linspace(kmin, kmax, ksteps1)
        # qy = np.linspace(kmin, kmax, ksteps2)
        # qx_grid, qy_grid = np.meshgrid(qx, qy)
        # t0 = time()
        # interp = griddata(
        #     points = (structure_fact[:,dim1],structure_fact[:,dim2]),
        #     values = structure_fact[:,-1],
        #     xi = (qx_grid, qy_grid),
        #     method='nearest', fill_value=0.
        # )
        # structure_fact_out = gaussian_filter(interp, sigma=(sf_smearingx, sf_smearingy))
        # print(f'Interpolation took {(time()-t0)/60:.2f} minutes')
        for ii in trange(steps):
            sf_ii_1 = structure_fact[ii,dim1]
            sf_ii_2 = structure_fact[ii,dim2]
            sf_ii = structure_fact[ii, -1]
            res = NORM * sf_ii  * (np.exp(-(sf_ii_1-kgridx)**2 / sf_smearingx**2 / 2))
            structure_fact_out[:,:] += res * (np.exp(-(sf_ii_2-kgridy)**2 / sf_smearingy**2 / 2))

    NK_TOT = ksteps1*ksteps2
    acc = 0
    if rotation is not None:
        vals = np.zeros((NK_TOT, 4))
        for ik in range(ksteps1):
            for iky in range(ksteps2):
                vals[acc, :] = np.array([kgridx[ik], kgridy.T[iky], plane_val, structure_fact_out[ik,iky]])
                acc += 1
        if rotate_broadened:
            Rmat = np.linalg.inv(Rmat)
            ORIGIN = np.average(vals[:,:3], axis=0)
            vals[:,:3] = np.transpose(Rmat @ (vals[:,:3]-ORIGIN).T) + ORIGIN
    else:
        vals = np.zeros((NK_TOT, 3))
        for ik in range(ksteps1):
            for iky in range(ksteps2):
                vals[acc, :] = np.array([kgridx[ik], kgridy.T[iky], structure_fact_out[ik,iky]])
                acc += 1

    vals[:,-1] *= Np**(-2)
    return vals

